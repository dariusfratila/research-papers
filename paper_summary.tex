\documentclass[3p,times]{elsarticle}
\usepackage{ecrc}
\usepackage[bookmarks=false]{hyperref}
\hypersetup{
    colorlinks,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue
}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{comment}
\usepackage[figuresright]{rotating}
\usepackage{float}
\usepackage{pifont} 

\firstpage{1}

\runauth{Darius Fratila}

\begin{document}    
\begin{frontmatter}

\dochead{\huge{Machine Learning Course (ML)}}

\title{Advancements in Object Localization and Detection Using Deep Learning Architectures}

\author{Darius Fratila} 

\address{Department of Computer Science, Babe\c s-Bolyai University\\1, M. Kogalniceanu Street, 400084, Cluj-Napoca, Romania\\E-mail: darius.fratila@stud.ubbcluj.ro}

\begin{abstract}
This paper provides a comprehensive overview of the evolution of object localization and detection, beginning with early feature-based methods such as Scale-Invariant Feature Transform (SIFT) and Histogram of Oriented Gradients (HOG), which were foundational but constrained by their inability to capture hierarchical semantic information. The advent of convolutional neural networks revolutionized object detection through architectures like R-CNN, which combined region proposals with CNN-based feature extraction and classification. Subsequent improvements in Fast R-CNN and Faster R-CNN introduced computational efficiencies, such as shared feature extraction and the integration of Region Proposal Networks (RPNs). These advancements significantly reduced inference time and improved mean average precision.  

Real-time detection frameworks such as YOLO and its iterations addressed the challenges of computational latency by treating object detection as a single-stage regression problem. YOLO achieved real-time performance while maintaining competitive accuracy. The Detection Transformer (DETR) marked a paradigm shift by leveraging attention mechanisms for end-to-end set prediction, eliminating anchor boxes and non-maximum suppression. Further improvements, such as Deformable DETR and Swin Transformer V2, addressed convergence speed and scalability, demonstrating state-of-the-art performance on benchmarks like COCO and ImageNet-V2.

Current research trends include anchor-free models, such as FCOS and CenterNet, which simplify detection pipelines, and frameworks like YOLOR, which integrate explicit and implicit knowledge for enhanced multi-task capabilities. Despite these advancements, challenges remain in detecting small objects, optimizing resource efficiency for deployment on edge devices, and addressing ethical concerns such as bias and privacy. Future work focuses on enhancing transformer-based models, developing lightweight architectures, and ensuring fairness in real-world applications.
\end{abstract}

\begin{keyword} 
Object Detection \sep Convolutional Neural Networks \sep R-CNN \sep Fast R-CNN \sep Faster R-CNN \sep YOLO \sep Real-Time Detection \sep Transformers \sep Object Localization \sep Deformable DETR
\end{keyword}

\end{frontmatter}

\end{document}
